{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## IMDB, Amazon and Yelp review classification \r\n",
    " - This project is for classification of different reviews of Imdb,Amazon and yelp.\r\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importing dependencies\r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a. Importing & pre-processing the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load the dataset\r\n",
    "data_yelp = pd.read_csv('yelp_labelled.txt',sep='\\t',header=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# showing few datasets\r\n",
    "data_yelp.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0                           Wow... Loved this place.  1\n",
       "1                                 Crust is not good.  0\n",
       "2          Not tasty and the texture was just nasty.  0\n",
       "3  Stopped by during the late May bank holiday of...  1\n",
       "4  The selection on the menu was great and so wer...  1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# assigning the names for columns\r\n",
    "column_name = ['Review','Feedback']\r\n",
    "data_yelp.columns = column_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data_yelp.head() , data_yelp.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(                                              Review  Feedback\n",
       " 0                           Wow... Loved this place.         1\n",
       " 1                                 Crust is not good.         0\n",
       " 2          Not tasty and the texture was just nasty.         0\n",
       " 3  Stopped by during the late May bank holiday of...         1\n",
       " 4  The selection on the menu was great and so wer...         1,\n",
       " (1000, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# loading the amazon dataset\r\n",
    "data_amazon = pd.read_csv('amazon_cells_labelled.txt',sep='\\t',header=None)\r\n",
    "# assigining same column name for amazon daatset\r\n",
    "data_amazon.columns = column_name\r\n",
    "# showing head data after adding column names\r\n",
    "data_amazon.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Feedback\n",
       "0  So there is no way for me to plug it in here i...         0\n",
       "1                        Good case, Excellent value.         1\n",
       "2                             Great for the jawbone.         1\n",
       "3  Tied to charger for conversations lasting more...         0\n",
       "4                                  The mic is great.         1"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data_amazon.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# loading Imdb dataset\r\n",
    "data_Imdb = pd.read_csv('imdb_labelled.txt',sep='\\t',header=None)\r\n",
    "data_Imdb.columns = column_name\r\n",
    "data_Imdb.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Feedback\n",
       "0  A very, very, very slow-moving, aimless movie ...         0\n",
       "1  Not sure who was more lost - the flat characte...         0\n",
       "2  Attempting artiness with black & white and cle...         0\n",
       "3       Very little music or anything to speak of.           0\n",
       "4  The best scene in the movie was when Gerardo i...         1"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data_Imdb.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(748, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# now ,we will append all the dataset into a single data\r\n",
    "data = data_yelp.append([data_amazon,data_Imdb],ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "data.shape, data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2748, 2),\n",
       "                                               Review  Feedback\n",
       " 0                           Wow... Loved this place.         1\n",
       " 1                                 Crust is not good.         0\n",
       " 2          Not tasty and the texture was just nasty.         0\n",
       " 3  Stopped by during the late May bank holiday of...         1\n",
       " 4  The selection on the menu was great and so wer...         1)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# checking if there is any null value in data\r\n",
    "data.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Review      0\n",
       "Feedback    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "data['Feedback'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    1386\n",
       "0    1362\n",
       "Name: Feedback, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "x = data['Review']\r\n",
    "y = data['Feedback']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b. Data Cleaning\r\n",
    " - In this we will remove all our stopwords, punctuations and we will apply lemmatization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import string\r\n",
    "punct = string.punctuation\r\n",
    "print(punct)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "stopwords = list(STOP_WORDS)\r\n",
    "print(stopwords)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['all', 'there', 'eleven', 'many', 'whatever', 'than', 'mostly', 'go', 'anyway', 'beforehand', 'used', 'hence', 'sometimes', 'hers', 'yourselves', 'neither', 'therein', 'side', 'although', 'about', 'only', 'nevertheless', 'nothing', 'six', '‘ll', 'less', '’s', 'onto', 'its', 'ours', 'namely', 'thereafter', 'in', 'towards', 'often', 'yourself', 'to', 'make', 'per', 'four', 'nowhere', 'something', 'everywhere', 'which', '‘s', 'amongst', 'everyone', 'thereby', 'and', 'how', 'however', 'might', '’re', 'had', 'whether', 'unless', 'yet', 'at', 'whoever', 'fifty', 'three', 'did', \"'s\", 'same', 'whom', 'eight', 'see', 'more', 'quite', 'put', 'on', 'the', 'nine', 'full', 're', 'around', 'us', '‘ve', 'others', 'everything', 'somehow', 'third', 'will', 'why', 'hereafter', 'we', 'via', 'afterwards', 'indeed', 'twelve', 'besides', 'moreover', 'was', 'done', 'or', 'must', 'most', 'anything', 'noone', 'their', 'otherwise', 'enough', 'get', 'your', 'last', 'seem', 'itself', 'herein', '‘m', 'been', 'various', \"'ll\", 'whence', 'i', 'thereupon', 'well', 'latterly', 'sixty', 'by', 'without', 'under', 'ever', 'whereas', 'both', 'now', 'next', \"'re\", 'himself', 'before', 'then', 'once', 'not', 'throughout', 'could', 'though', 'those', 'still', 'already', 'being', 'whither', \"'ve\", 'our', 'such', 'much', '‘d', 'am', 'if', 'using', \"'d\", 'top', 'during', 'ten', 'whenever', 'here', 'too', 'fifteen', 'really', 'into', 'thence', 'made', 'several', 'toward', 'whole', 'but', 'further', 'among', 'of', 'up', 'between', 'also', 'have', 'be', 'never', 'these', 'along', 'no', 'through', 'due', 'each', 'it', 'own', 'until', 'because', 'bottom', 'mine', 'almost', 'for', 'are', 'has', '’ll', 'so', 'just', 'her', 'becomes', 'either', 'that', 'down', 'give', 'seeming', 'sometime', 'may', 'below', 'does', 'themselves', 'two', 'him', 'take', 'an', 'none', 'hereupon', 'some', 'forty', 'nor', 'is', 'becoming', 'whereby', '’ve', 'anywhere', 'alone', 'yours', 'should', 'wherein', 'while', 'do', 'first', 'his', 'from', 'this', 'former', 'every', 'empty', 'he', 'she', 'they', 'somewhere', 'anyhow', 'very', 'seemed', 'where', 'you', 'myself', 'another', 'therefore', 'beyond', 'show', 'perhaps', 'seems', 'n‘t', 'with', 'name', 'cannot', 'off', 'became', 'above', 'regarding', 'within', 'any', 'them', 'can', 'move', 'herself', 'wherever', 'over', 'someone', 'out', 'become', 'since', 'twenty', 'one', 'beside', 'nobody', 'other', 'call', 'a', 'meanwhile', '’m', 'part', 'formerly', 'against', \"n't\", 'thus', 'few', 'n’t', 'whereupon', 'as', 'would', 'ourselves', 'after', \"'m\", 'rather', 'hereby', 'again', 'amount', '’d', '‘re', 'keep', 'who', 'me', 'ca', 'elsewhere', 'together', 'when', 'anyone', 'hundred', 'latter', 'front', 'whereafter', 'say', 'upon', 'what', 'always', 'please', 'behind', 'else', 'five', 'except', 'even', 'doing', 'thru', 'least', 'my', 'serious', 'were', 'across', 'back', 'whose']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import spacy \r\n",
    "\r\n",
    "nlp = spacy.load('en_core_web_sm')\r\n",
    "\r\n",
    "def text_data_cleaning(sentence):\r\n",
    "  doc = nlp(sentence)\r\n",
    "\r\n",
    "  tokens = [] # list of tokens\r\n",
    "  for token in doc:\r\n",
    "    if token.lemma_ != \"-PRON-\":\r\n",
    "      temp = token.lemma_.lower().strip()\r\n",
    "    else:\r\n",
    "      temp = token.lower_   # since there is no lemma for proper noun we are directly taking the lower case\r\n",
    "    tokens.append(temp)\r\n",
    "  \r\n",
    "  cleaned_tokens = []\r\n",
    "  for token in tokens:\r\n",
    "    if token not in stopwords and token not in punct:\r\n",
    "      cleaned_tokens.append(token)\r\n",
    "  return cleaned_tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# example of data we cleaned\r\n",
    "text_data_cleaning('good morning, it seems a very sunny day !')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['good', 'morning', 'sunny', 'day']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c. TF-IDF vectorization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=text_data_cleaning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "classifier = LinearSVC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d. Training our model\r\n",
    " - splitting our dataset into training and test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "x_train.shape, x_test.shape\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1923,), (825,))"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "x_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "646                                       What a mistake.\n",
       "2166    Damian is so talented and versatile in so many...\n",
       "1686    The instructions didn't explain that a microph...\n",
       "1368                                     Love This Phone.\n",
       "47            The burger is good beef, cooked just right.\n",
       "Name: Review, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# fitting our x_train and y_train\r\n",
    "clf = Pipeline([('tfidf',tfidf), ('clf',classifier)])\r\n",
    "# it will first do vectorization and then it will do classification"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "clf.fit(x_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(tokenizer=<function text_data_cleaning at 0x000001B7FAD46D30>)),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### e. prediction of our model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "y_pred = clf.predict(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[311, 103],\n",
       "       [ 77, 334]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "accuracy_score(y_test,y_pred) *100  # we got a 78% accuracy !!"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78.18181818181819"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}